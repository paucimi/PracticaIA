{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6438f6d04043459782d5840ee8f335c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instalo las dependencias necesarias\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate peft bitsandbytes trl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.11.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (2.4.1+cu124)\n",
      "Requirement already satisfied: transformers>=4.40.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (4.46.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (1.0.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (3.1.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (0.9.16)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from trl) (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch>=1.4.0->trl) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from transformers>=4.40.0->trl) (4.66.5)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: eval-type-backport>=0.1.3 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (0.2.2)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tyro>=0.5.11->trl) (4.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from accelerate->trl) (7.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from datasets->trl) (3.10.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->transformers>=4.40.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->transformers>=4.40.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.19.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from typeguard>=4.0.0->tyro>=0.5.11->trl) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas->datasets->trl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas->datasets->trl) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas->datasets->trl) (2025.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from importlib-metadata>=3.6->typeguard>=4.0.0->tyro>=0.5.11->trl) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->trl) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación del Dataset\n",
    "# Creamos un conjunto de datos de ejemplo en español que contenga preguntas típicas de asistencia al cliente y sus respuestas.\n",
    "data = [\n",
    "    {\n",
    "        \"instruccion\": \"¿Cuál es el horario de atención al cliente?\",\n",
    "        \"respuesta\": \"Nuestro horario de atención es de lunes a viernes de 9am a 6pm.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Cómo puedo cancelar mi pedido?\",\n",
    "        \"respuesta\": \"Puedes cancelar tu pedido contactando a nuestro equipo de soporte dentro de las 24 horas posteriores a la compra.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Qué métodos de pago aceptan?\",\n",
    "        \"respuesta\": \"Aceptamos tarjetas de crédito, débito y PayPal.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Tienen política de devoluciones?\",\n",
    "        \"respuesta\": \"Sí, contamos con una política de devoluciones de 30 días. Revisa nuestra web para más detalles.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Cómo puedo rastrear mi envío?\",\n",
    "        \"respuesta\": \"Puedes rastrear tu envío con el número de seguimiento que te enviamos por correo electrónico.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Cómo puedo actualizar mi información personal?\",\n",
    "        \"respuesta\": \"Para actualizar tus datos personales, ingresa a tu cuenta y selecciona la opción 'Perfil' para editar tu información.\"\n",
    "    },\n",
    "    {   \"instruccion\": \"¿Qué hago si no recibo mi pedido?\",\n",
    "        \"respuesta\": \"Si no has recibido tu pedido, por favor contacta a nuestro equipo de soporte para verificar el estado del envío.\"\n",
    "    },\n",
    "   {\n",
    "        \"instruccion\": \"¿Puedo modificar mi pedido después de realizarlo?\",\n",
    "        \"respuesta\": \"Una vez realizado el pedido, solo se pueden realizar modificaciones contactando a nuestro equipo de soporte, siempre que el pedido no haya sido procesado.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Cómo puedo obtener una factura de mi compra?\",\n",
    "        \"respuesta\": \"Puedes solicitar una factura de tu compra a través de la sección 'Mis Compras' en tu cuenta o contactando a nuestro soporte.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Qué debo hacer si mi producto llega dañado?\",\n",
    "        \"respuesta\": \"Si recibes un producto dañado, contacta a nuestro servicio de atención al cliente inmediatamente para gestionar la devolución o el reemplazo.\"\n",
    "    },\n",
    "    {\n",
    "        \"instruccion\": \"¿Tienen ofertas o descuentos especiales?\",\n",
    "        \"respuesta\": \"Sí, periódicamente ofrecemos promociones y descuentos especiales. Te recomendamos suscribirte a nuestro boletín para estar informado.\"\n",
    "    },   \n",
    "]\n",
    "\n",
    "\n",
    "# Unificamos la instrucción y la respuesta en un formato de prompt\n",
    "for registro in data:\n",
    "    registro[\"text\"] = (\n",
    "        f\"### Instrucción:\\n{registro['instruccion']}\\n\\n\"\n",
    "        f\"### Respuesta:\\n{registro['respuesta']}\"\n",
    "    )\n",
    "\n",
    "# Convertimos la lista en un Dataset de Hugging Face\n",
    "dataset = Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Carga y Configuración del Modelo con QLoRA\n",
    "# Usamos un modelo preentrenado en español; en este ejemplo empleamos \"datificate/gpt2-small-spanish\".\n",
    "# Configuramos la cuantización a 4 bits mediante BitsAndBytes para hacer el entrenamiento más eficiente.\n",
    "model_name = \"datificate/gpt2-small-spanish\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\", truncation=True)\n",
    "# Si no tiene pad_token, lo añadimos manualmente y redimensionamos las embeddings del modelo\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    \n",
    "# Aseguramos que el pad_token esté definido\n",
    "print(\"Pad Token:\", tokenizer.pad_token)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Cargamos el modelo en modo 4-bit\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,   # Permite ejecutar código remoto si el modelo lo requiere\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Si hemos añadido un nuevo pad_token, redimensionamos las embeddings\n",
    "if tokenizer.pad_token_id is None or tokenizer.pad_token_id >= model.config.vocab_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "# Adjuntar adaptadores (LoRA) para que el modelo cuantizado sea entrenable\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # Ajustamos para modelos de lenguaje causal\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de los Parámetros de Entrenamiento\n",
    "# Se definen los argumentos de entrenamiento para ajustar el modelo. \n",
    "# Se han seleccionado hiperparámetros razonables, pero puedes ajustar según tus recursos y resultados esperados.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./resultados\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=100,\n",
    "    logging_steps=20,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,          # Usamos FP16 para acelerar el entrenamiento en GPUs compatibles\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a73929f4869469da73c5bf3121ffc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pauci\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4ec437fd514494b96ae7c57cf99d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.5458, 'train_samples_per_second': 71.159, 'train_steps_per_second': 6.469, 'train_loss': 7.514565277099609, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=7.514565277099609, metrics={'train_runtime': 1.5458, 'train_samples_per_second': 71.159, 'train_steps_per_second': 6.469, 'total_flos': 2857548533760.0, 'train_loss': 7.514565277099609, 'epoch': 10.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-Tuning del Modelo usando SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=100,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "# Inicia el proceso de entrenamiento\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de Inferencia: Generación de Respuestas\n",
    "def generar_respuesta(instruccion):\n",
    "    # Se arma el prompt en el mismo formato del entrenamiento\n",
    "    prompt = f\"### Instrucción:\\n{instruccion}\\n\\n### Respuesta:\"\n",
    "    # Usamos el tokenizer para obtener input_ids y attention_mask\n",
    "    encoded_input = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = encoded_input[\"input_ids\"].to(model.device)\n",
    "    attention_mask = encoded_input[\"attention_mask\"].to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=100,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            attention_mask=attention_mask, \n",
    "            )\n",
    "    \n",
    "    texto_generado = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    if \"### Respuesta:\" in texto_generado:\n",
    "        respuesta = texto_generado.split(\"### Respuesta:\")[-1].strip()\n",
    "    else:\n",
    "        respuesta = texto_generado.strip()\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta del Cliente:\n",
      "¿Cómo puedo cambiar mi dirección de envío?\n",
      "\n",
      "Respuesta del Chatbot:\n",
      "¡Dáviento!\n",
      "!# ##\n",
      "El poder de la mente es una idea que un individuo está siendo capaz de usar un lenguaje humano.\n",
      "Es una forma de pensamiento con sentido y una filosofía de mente. Es un concepto que se caracteriza por su carácter de pensar y no tener sentido. El sujeto es un sujeto, un tipo, una mente, y la forma\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos de Uso del Chatbot\n",
    "pregunta_cliente = \"¿Cómo puedo cambiar mi dirección de envío?\"\n",
    "respuesta = generar_respuesta(pregunta_cliente)\n",
    "\n",
    "print(\"Pregunta del Cliente:\")\n",
    "print(pregunta_cliente)\n",
    "print(\"\\nRespuesta del Chatbot:\")\n",
    "print(respuesta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pregunta:\n",
      "¿Cuáles son los métodos de pago disponibles?\n",
      "Respuesta:\n",
      "Los métodos usados para las actividades en línea, en la mayoría de los países, son a menudo aquellos que se han interesado en las habilidades de cualquier persona o entidad. Por ejemplo, los medios de comunicación de la época, tales como radio, televisión, periódicos, revistas, etc., los autores de obras de teatro, las historias, películas, cine, videojuegos, literatura\n",
      "\n",
      "Pregunta:\n",
      "¿Tienen política de devoluciones extendida?\n",
      "Respuesta:\n",
      "\"¿Asesoramiento de una nueva dimensión\"\n",
      "- “¿Quién ha vuelto a la izquierda? \n",
      "\"En el debate de los candidatos de la coalición \"Núcleo\" y \"Los liberales\" de 2004, el grupo de \"Nacionalistas\" declaró: \"No se trata de un grupo, sino de personas que quieren convertirse en un partido político.\n",
      "\n",
      "Pregunta:\n",
      "¿A qué hora cierran sus oficinas de atención?\n",
      "Respuesta:\n",
      "¿Qué qué se siente??;\n",
      " ## Revisar: No.\n",
      "Maude es una serie de televisión estadounidense de comedia, escrita por el director estadounidense Dan Kinski. La serie se estrenó el 4 de mayo de 2019, y se emitió el 16 de febrero de 2020. El creador de la serie, Dan C. C., la llamó «una de\n"
     ]
    }
   ],
   "source": [
    "otras_preguntas = [\n",
    "    \"¿Cuáles son los métodos de pago disponibles?\",\n",
    "    \"¿Tienen política de devoluciones extendida?\",\n",
    "    \"¿A qué hora cierran sus oficinas de atención?\"\n",
    "]\n",
    "\n",
    "for pregunta in otras_preguntas:\n",
    "    print(\"\\nPregunta:\")\n",
    "    print(pregunta)\n",
    "    print(\"Respuesta:\")\n",
    "    print(generar_respuesta(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot_asistencia_cliente\\\\tokenizer_config.json',\n",
       " 'chatbot_asistencia_cliente\\\\special_tokens_map.json',\n",
       " 'chatbot_asistencia_cliente\\\\vocab.json',\n",
       " 'chatbot_asistencia_cliente\\\\merges.txt',\n",
       " 'chatbot_asistencia_cliente\\\\added_tokens.json',\n",
       " 'chatbot_asistencia_cliente\\\\tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Guardado del Modelo y Tokenizador\n",
    "model.save_pretrained(\"chatbot_asistencia_cliente\")\n",
    "tokenizer.save_pretrained(\"chatbot_asistencia_cliente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
